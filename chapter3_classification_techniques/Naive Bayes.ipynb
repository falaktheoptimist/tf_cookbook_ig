{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import colors\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import logsumexp\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
    "# The digits dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFNaiveBayesClassifier:\n",
    "    dist = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Separate training points by class (nb_classes * nb_samples * nb_features)\n",
    "        unique_y = np.unique(y)\n",
    "        points_by_class = [\n",
    "            [x for x, t in zip(X, y) if t == c]\n",
    "            for c in unique_y]\n",
    "        minsize = 100000\n",
    "        for p in points_by_class:\n",
    "            minsize = min(minsize, len(p))\n",
    "        for i, p in enumerate(points_by_class):\n",
    "            points_by_class[i] = points_by_class[i][:minsize]\n",
    "        points_by_class = np.array(points_by_class)\n",
    "        print(points_by_class.shape)\n",
    "        # Estimate mean and variance for each class / feature\n",
    "        # shape: nb_classes * nb_features\n",
    "        mean, var = tf.nn.moments(tf.constant(points_by_class), axes=[1])\n",
    "\n",
    "        # Create a 3x2 univariate normal distribution with the \n",
    "        # known mean and variance\n",
    "        self.dist = tf.distributions.Normal(loc=mean, scale=tf.sqrt(var))\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert self.dist is not None\n",
    "\n",
    "        nb_classes, nb_features = map(int, self.dist.scale.shape)\n",
    "\n",
    "        # Conditional probabilities log P(x|c) with shape\n",
    "        # (nb_samples, nb_classes)\n",
    "        cond_probs = tf.reduce_sum(\n",
    "            self.dist.log_prob(\n",
    "                tf.reshape(\n",
    "                    tf.tile(X, [1, nb_classes]), [-1, nb_classes, nb_features])),\n",
    "            axis=2)\n",
    "\n",
    "        # uniform priors\n",
    "        priors = np.log(np.array([1. / nb_classes] * nb_classes))\n",
    "\n",
    "        # posterior log probability, log P(c) + log P(x|c)\n",
    "        cond_probs = tf.cast(cond_probs, tf.float64)\n",
    "        joint_likelihood = tf.add(priors, cond_probs)\n",
    "\n",
    "        # normalize to get (log)-probabilities\n",
    "        norm_factor = tf.reduce_logsumexp(\n",
    "            joint_likelihood, axis=1, keep_dims=True)\n",
    "        log_prob = joint_likelihood - norm_factor\n",
    "        # exp to get the actual probabilities\n",
    "        return tf.exp(log_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 264, 100)\n"
     ]
    }
   ],
   "source": [
    "X = mnist.train.images[:3000,200:300]+1e-8\n",
    "y = mnist.train.labels[:3000]\n",
    "\n",
    "tf_nb = TFNaiveBayesClassifier()\n",
    "tf_nb.fit(X, y)\n",
    "\n",
    "\n",
    "s = tf.Session()\n",
    "Z = s.run(tf_nb.predict(X))\n",
    "predicted_label = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 1, 2, ..., 2, 2, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21533333333333332"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y==predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
